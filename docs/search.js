window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "rate_severity_of_toxic_comments", "modulename": "rate_severity_of_toxic_comments", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.dataset", "modulename": "rate_severity_of_toxic_comments.dataset", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.dataset.BinarizedDataset", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "BinarizedDataset", "type": "class", "doc": "<p>Class containing a binarized dataset.</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nDataFrame containing the dataset.</li>\n<li><strong>max_len</strong> (int):\nMaximum length of the dataset.</li>\n<li><strong>tokenizer</strong> (transformers.tokenization_utils.PreTrainedTokenizer):\nText tokenizer.</li>\n<li><strong>text</strong> (list):\nList of comments.</li>\n<li><strong>metric</strong> (list):\nList of preprocessing metrics of comments.</li>\n<li><strong>target</strong> (list):\nList of targets.</li>\n</ul>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>__init__(self, df, tokenizer, max_length)\n    Initializes the dataset.\n__len__(self)\n    Returns the length of the dataset.\n__getitem__(self, index)\n    Returns a dataset item.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "rate_severity_of_toxic_comments.dataset.BinarizedDataset.__init__", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "BinarizedDataset.__init__", "type": "function", "doc": "<p>Initializes the dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (df):\nDataFrame for the dataset.</li>\n<li><strong>tokenizer</strong> (transformers.tokenization_utils.PreTrainedTokenizer):\nText tokenizer for the dataset.</li>\n<li><strong>max_length</strong> (int):\nMaximum length of the dataset.</li>\n</ul>\n", "signature": "(self, df, tokenizer, max_length)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.dataset.PairwiseDataset", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "PairwiseDataset", "type": "class", "doc": "<p>Class containing a pairwise dataset.</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nDataFrame containing the dataset.</li>\n<li><strong>max_len</strong> (int):\nMaximum length of the dataset.</li>\n<li><strong>tokenizer</strong> (transformers.tokenization_utils.PreTrainedTokenizer):\nText tokenizer.</li>\n<li><strong>more_toxic</strong> (list):\nList of more toxic comments.</li>\n<li><strong>more_toxic_metric</strong> (list):\nList of preprocessing metrics of more toxic comments.</li>\n<li><strong>less_toxic</strong> (list):\nList of less toxic comments.</li>\n<li><strong>less_toxic_metric</strong> (list):\nList of preprocessing metrics of less toxic comments.</li>\n</ul>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>__init__(self, df, tokenizer, max_length)\n    Initializes the dataset.\n__len__(self)\n    Returns the length of the dataset.\n__getitem__(self, index)\n    Returns a dataset item.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "rate_severity_of_toxic_comments.dataset.PairwiseDataset.__init__", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "PairwiseDataset.__init__", "type": "function", "doc": "<p>Initializes the dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (df):\nDataFrame for the dataset.</li>\n<li><strong>tokenizer</strong> (transformers.tokenization_utils.PreTrainedTokenizer):\nText tokenizer for the dataset.</li>\n<li><strong>max_length</strong> (int):\nMaximum length of the dataset.</li>\n</ul>\n", "signature": "(self, df, tokenizer, max_length)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.dataset.ScoredDataset", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "ScoredDataset", "type": "class", "doc": "<p>Class containing a binarized dataset.</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nDataFrame containing the dataset.</li>\n<li><strong>max_len</strong> (int):\nMaximum length of the dataset.</li>\n<li><strong>tokenizer</strong> (transformers.tokenization_utils.PreTrainedTokenizer):\nText tokenizer.</li>\n<li><strong>text</strong> (list):\nList of comments.</li>\n<li><strong>sample_weight</strong> (list):\nList of sample weights.</li>\n<li><strong>preprocessing_metric</strong> (list):\nList of preprocessing metrics of comments.</li>\n<li><strong>target</strong> (list):\nList of targets.</li>\n</ul>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>__init__(self, df, tokenizer, max_length)\n    Initializes the dataset.\n__len__(self)\n    Returns the length of the dataset.\n__getitem__(self, index)\n    Returns a dataset item.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "rate_severity_of_toxic_comments.dataset.ScoredDataset.__init__", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "ScoredDataset.__init__", "type": "function", "doc": "<p>Initializes the dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (df):\nDataFrame for the dataset.</li>\n<li><strong>tokenizer</strong> (transformers.tokenization_utils.PreTrainedTokenizer):\nText tokenizer for the dataset.</li>\n<li><strong>max_length</strong> (int):\nMaximum length of the dataset.</li>\n</ul>\n", "signature": "(self, df, tokenizer, max_length)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.dataset.build_dataloaders", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "build_dataloaders", "type": "function", "doc": "<p>Builds the dataloader.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>datasets</strong> (list):\nList of datasets.</li>\n<li><strong>batch_sizes</strong> (list):\nList of batch sizes.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>data_loaders</strong> (list):\nList of dataloaders.</li>\n</ul>\n", "signature": "(datasets, batch_sizes)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.dataset.build_dataset", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "build_dataset", "type": "function", "doc": "<p>Builds the dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nDataFrame containing the dataset.</li>\n<li><strong>dataset_params</strong> (dict):\nDataset parameters.</li>\n<li><strong>model_params</strong> (dict):\nModel parameters.</li>\n<li><strong>tokenizer</strong> (transformers.tokenization_utils.PreTrainedTokenizer):\nText tokenizer.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>dataset</strong> (torch.utils.data.dataset.Dataset):\nDataset to return.</li>\n</ul>\n", "signature": "(df, dataset_params, model_params, tokenizer)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.dataset.get_sample_weights", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "get_sample_weights", "type": "function", "doc": "<p>Returns the sample weights.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nDataFrame containing the dataset.</li>\n<li><strong>target_col_name</strong> (str):\nName of the target column.</li>\n<li><strong>bins</strong> (int, default 100):\nNumber of bins.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>binned_targets</strong> (pandas.core.series.Series):\nSample weights.</li>\n</ul>\n", "signature": "(df, target_col_name, bins=100)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.dataset.load_dataframe", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "load_dataframe", "type": "function", "doc": "<p>Loads the dataframe.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>run_mode</strong> (str):\nRun mode.</li>\n<li><strong>dataset_params</strong> (dict):\nDataset parameters.</li>\n<li><strong>model_params</strong> (dict):\nModel parameters.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nLoaded dataframe.</li>\n</ul>\n", "signature": "(run_mode, dataset_params, model_params)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.dataset.split_dataset", "modulename": "rate_severity_of_toxic_comments.dataset", "qualname": "split_dataset", "type": "function", "doc": "<p>Splits the dataset.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataframe</strong> (pandas.core.frame.DataFrame):\nDataFrame containing the dataset.</li>\n<li><strong>target_col_name</strong> (str):\nName of the target column.</li>\n<li><strong>seed</strong> (int):\nSeed for random state.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>splitting</strong> (list):\nList of dataset splittings.</li>\n</ul>\n", "signature": "(dataframe: pandas.core.frame.DataFrame, target_col_name, seed)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.embedding", "modulename": "rate_severity_of_toxic_comments.embedding", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.embedding.build_embedding_matrix", "modulename": "rate_severity_of_toxic_comments.embedding", "qualname": "build_embedding_matrix", "type": "function", "doc": "<p>Builds the embedding matrix.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>embedding_model</strong> (gensim.models.keyedvectors.KeyedVectors):\nEmbedding model.</li>\n<li><strong>embedding_dim</strong> (int):\nEmbedding dimension.</li>\n<li><strong>vocab</strong> (dict):\nVocabulary.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>embedding_matrix</strong> (numpy.ndarray):\nEmbedding matrix.</li>\n</ul>\n", "signature": "(\n    embedding_model: gensim.models.keyedvectors.KeyedVectors,\n    embedding_dim,\n    vocab\n) -> numpy.ndarray", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.embedding.check_OOV_terms", "modulename": "rate_severity_of_toxic_comments.embedding", "qualname": "check_OOV_terms", "type": "function", "doc": "<p>Highlights out-of-vocabulary terms.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>embedding_model</strong> (gensim.models.keyedvectors.KeyedVectors):\nEmbedding model.</li>\n<li><strong>vocab</strong> (dict):\nVocabulary.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>oov</strong> (list):\nList of out-of-vocabulary terms.</li>\n</ul>\n", "signature": "(embedding_model: gensim.models.keyedvectors.KeyedVectors, vocab)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.embedding.count_OOV_frequency", "modulename": "rate_severity_of_toxic_comments.embedding", "qualname": "count_OOV_frequency", "type": "function", "doc": "<p>Counts out-of-vocabulary frequency.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nDataset.</li>\n<li><strong>cols</strong> (list):\nList of column names.</li>\n<li><strong>oov</strong> (list):\nList of out-of-vocabulary terms.</li>\n</ul>\n", "signature": "(df, cols, oov)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.embedding.load_embedding_model", "modulename": "rate_severity_of_toxic_comments.embedding", "qualname": "load_embedding_model", "type": "function", "doc": "<p>Loads a pre-trained word embedding model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_params</strong> (dict):\nModel parameters.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>emb_model</strong> (gensim.models.keyedvectors.KeyedVectors):\nEmbedding model.</li>\n</ul>\n", "signature": "(model_params) -> gensim.models.keyedvectors.KeyedVectors", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.metrics", "modulename": "rate_severity_of_toxic_comments.metrics", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.metrics.TrainLoopStatisticsManager", "modulename": "rate_severity_of_toxic_comments.metrics", "qualname": "TrainLoopStatisticsManager", "type": "class", "doc": "<p>Class managing the statistics of the train loop.</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>model</strong> (torch.nn.modules.module.Module):\nNeural network model.</li>\n<li><strong>early_stopping_patience</strong> (int):\nEarly stopping parameter.</li>\n<li><strong>verbose</strong> (bool):\nVerbosity flag.</li>\n<li><strong>use_wandb</strong> (bool):\nWeights &amp; Biases flag.</li>\n<li><strong>counter</strong> (int):\nEarly stopping counter.</li>\n<li><strong>best_val_loss</strong> (float):\nBest validation loss value.</li>\n<li><strong>train_loss_history</strong> (list):\nHistory of training loss.</li>\n<li><strong>val_loss_history</strong> (list):\nHistory of validation loss.</li>\n<li><strong>early_stop</strong> (bool):\nEarly stopping flag.</li>\n<li><strong>best_model_wts</strong> (torch.nn.modules.module.Module):\nBest neural network model.</li>\n</ul>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>__init__(self, model, early_stopping_patience=7, verbose=True, use_wandb=False)\n    Initializes the manager.\nregisterEpoch(self, metrics_train: dict, metrics_val: dict, lr, epoch, time_start, time_end, early_stop_delta_sensibility=0.01)\n    Registers an epoch.\ngetLossHistory(self)\n    Returns the loss history.\n_checkEarlyStop(self, val_loss, delta_sensibility)\n    Checks for early stopping conditions.</p>\n"}, {"fullname": "rate_severity_of_toxic_comments.metrics.TrainLoopStatisticsManager.__init__", "modulename": "rate_severity_of_toxic_comments.metrics", "qualname": "TrainLoopStatisticsManager.__init__", "type": "function", "doc": "<p>Initializes the manager.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model</strong> (torch.nn.modules.module.Module):\nNeural network model.</li>\n<li><strong>early_stopping_patience</strong> (int, default 7):\nEarly stopping parameter.</li>\n<li><strong>verbose</strong> (bool, default True):\nVerbosity flag.</li>\n<li><strong>use_wandb</strong> (bool, default False):\nWeights &amp; Biases flag.</li>\n</ul>\n", "signature": "(\n    self,\n    model,\n    early_stopping_patience=7,\n    verbose=True,\n    use_wandb=False\n)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.metrics.TrainLoopStatisticsManager.registerEpoch", "modulename": "rate_severity_of_toxic_comments.metrics", "qualname": "TrainLoopStatisticsManager.registerEpoch", "type": "function", "doc": "<p>Registers an epoch.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>metrics_train</strong> (dict):\nTraining metrics.</li>\n<li><strong>metrics_val</strong> (dict):\nValidation metrics.</li>\n<li><strong>lr</strong> (float):\nLearning rate.</li>\n<li><strong>epoch</strong> (int):\nEpoch number.</li>\n<li><strong>time_start</strong> (float):\nEpoch starting time.</li>\n<li><strong>time_end</strong> (float):\nEpoch ending time.</li>\n<li><strong>early_stop_delta_sensibility</strong> (float, default 0.01):\nEarly stopping sensibility.</li>\n</ul>\n", "signature": "(\n    self,\n    metrics_train: dict,\n    metrics_val: dict,\n    lr,\n    epoch,\n    time_start,\n    time_end,\n    early_stop_delta_sensibility=0.01\n)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.metrics.TrainLoopStatisticsManager.getLossHistory", "modulename": "rate_severity_of_toxic_comments.metrics", "qualname": "TrainLoopStatisticsManager.getLossHistory", "type": "function", "doc": "<p>Returns the loss history.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>loss_history</strong> (dict):\nLoss history.</li>\n</ul>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.model", "modulename": "rate_severity_of_toxic_comments.model", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.model.PretrainedModel", "modulename": "rate_severity_of_toxic_comments.model", "qualname": "PretrainedModel", "type": "class", "doc": "<p>Class containing a pretrained neural network model.</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>model</strong> (torch.nn.modules.module.Module):\nNeural network model.</li>\n<li><strong>sig</strong> (torch.nn.modules.activation.Sigmoid):\nSigmoid layer.</li>\n<li><strong>fc</strong> (torch.nn.modules.linear.Linear):\nLinear layer.</li>\n</ul>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>__init__(self, model_name, dropout, output_features)\n    Initializes the model.\nforward(self, ids, mask, _)\n    Defines the computation performed at every call.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "rate_severity_of_toxic_comments.model.PretrainedModel.__init__", "modulename": "rate_severity_of_toxic_comments.model", "qualname": "PretrainedModel.__init__", "type": "function", "doc": "<p>Initializes the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>model_name</strong> (str):\nName of the model.</li>\n<li><strong>dropout</strong> (float):\nDropout parameter.</li>\n<li><strong>output_features</strong> (int):\nNumber of ouput features.</li>\n</ul>\n", "signature": "(self, model_name, dropout, output_features)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.model.PretrainedModel.forward", "modulename": "rate_severity_of_toxic_comments.model", "qualname": "PretrainedModel.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>ids</strong> (torch.Tensor):\nTensor of ids.</li>\n<li><strong>mask</strong> (torch.Tensor):\nTensor of masks.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>x</strong> (torch.Tensor):\nTensor to return.</li>\n</ul>\n", "signature": "(self, ids, mask, _)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.model.RecurrentModel", "modulename": "rate_severity_of_toxic_comments.model", "qualname": "RecurrentModel", "type": "class", "doc": "<p>Class containing a recurrent neural network model.</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>embedding</strong> (torch.nn.modules.sparse.Embedding):\nEmbedding lookup table.</li>\n<li><strong>recurrent</strong> (torch.nn.modules.rnn.RNNBase):\nRecurrent Neural Network.</li>\n<li><strong>preprocessing_metric</strong> (bool):\nPreprocessing metric flag.</li>\n<li><strong>drop</strong> (torch.nn.modules.dropout.Dropout):\nDropout layer.</li>\n<li><strong>relu</strong> (torch.nn.modules.activation.ReLU):\nReLU activation layer.</li>\n<li><strong>sig</strong> (torch.nn.modules.activation.Sigmoid):\nSigmoid layer.</li>\n<li><strong>fc</strong> (torch.nn.modules.linear.Linear):\nLinear layer.</li>\n</ul>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>__init__(self, embedding_matrix, dropout, hidden_dim, architecture, preprocessing_metric)\n    Initializes the model.\nforward(self, ids, mask, preprocessing_metric)\n    Defines the computation performed at every call.</p>\n", "bases": "torch.nn.modules.module.Module"}, {"fullname": "rate_severity_of_toxic_comments.model.RecurrentModel.__init__", "modulename": "rate_severity_of_toxic_comments.model", "qualname": "RecurrentModel.__init__", "type": "function", "doc": "<p>Initializes the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>embedding_matrix</strong> (numpy.ndarray):\nEmbedding matrix.</li>\n<li><strong>dropout</strong> (float):\nDropout parameter.</li>\n<li><strong>hidden_dim</strong> (int):\nHidden dimension.</li>\n<li><strong>architecture</strong> (str):\nName of architecture.</li>\n<li><strong>preprocessing_metric</strong> (bool):\nPreprocessing metric flag.</li>\n</ul>\n", "signature": "(\n    self,\n    embedding_matrix,\n    dropout,\n    hidden_dim,\n    architecture,\n    preprocessing_metric\n)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.model.RecurrentModel.forward", "modulename": "rate_severity_of_toxic_comments.model", "qualname": "RecurrentModel.forward", "type": "function", "doc": "<p>Defines the computation performed at every call.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>ids</strong> (torch.Tensor):\nTensor of ids.</li>\n<li><strong>mask</strong> (torch.Tensor):\nTensor of masks.</li>\n<li><strong>preprocessing_metric</strong> (torch.Tensor):\nTensor of preprocessing metric values.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>x</strong> (torch.Tensor):\nTensor to return.</li>\n</ul>\n", "signature": "(self, ids, mask, preprocessing_metric)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.model.create_model", "modulename": "rate_severity_of_toxic_comments.model", "qualname": "create_model", "type": "function", "doc": "<p>Returns a model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>run_mode</strong> (str):\nRun mode.</li>\n<li><strong>train_params</strong> (dict):\nTraining parameters.</li>\n<li><strong>model_params</strong> (dict):\nModel parameters.</li>\n<li><strong>support_bag</strong> (dict):\nConfiguration parameters.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>model</strong> (torch.nn.modules.module.Module):\nModel to return.</li>\n</ul>\n", "signature": "(run_mode, train_params, model_params, support_bag)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.preprocessing", "modulename": "rate_severity_of_toxic_comments.preprocessing", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.preprocessing.apply_preprocessing_pipelines", "modulename": "rate_severity_of_toxic_comments.preprocessing", "qualname": "apply_preprocessing_pipelines", "type": "function", "doc": "<p>Applies the preprocesssing pipelines to a text.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>text</strong> (str):\nText to preprocess.</li>\n<li><strong>pipelines</strong> (list):\nPipelines to execute.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>text</strong> (str):\nPreprocessed text.</li>\n<li><strong>metric</strong> (float):\nPreprocessing amount metric.</li>\n</ul>\n", "signature": "(text, pipelines)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.preprocessing.apply_preprocessing_pipeline", "modulename": "rate_severity_of_toxic_comments.preprocessing", "qualname": "apply_preprocessing_pipeline", "type": "function", "doc": "<p>Applies a preprocesssing pipeline to a text.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>text</strong> (str):\nText to preprocess.</li>\n<li><strong>metric</strong> (float):\nPreprocessing amount metric</li>\n<li><strong>pipeline</strong> (str):\nPipeline to execute.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>text</strong> (str):\nPreprocessed text.</li>\n<li><strong>metric</strong> (float):\nPreprocessing amount metric.</li>\n</ul>\n", "signature": "(text, metric, pipeline)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.tokenizer", "modulename": "rate_severity_of_toxic_comments.tokenizer", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.tokenizer.NaiveTokenizer", "modulename": "rate_severity_of_toxic_comments.tokenizer", "qualname": "NaiveTokenizer", "type": "class", "doc": "<p>Class containing a naive tokenizer.</p>\n\n<h6 id=\"attributes\">Attributes</h6>\n\n<ul>\n<li><strong>basic_tokenizer</strong> (transformers.models.bert.tokenization_bert.BasicTokenizer):\nBasic tokenizer.</li>\n</ul>\n\n<h6 id=\"methods\">Methods</h6>\n\n<p>__init__(self, do_lower_case=True, never_split=None, unk_token='[UNK]', pad_token='[PAD]', **kwargs)\n    Initializes the tokenizer.\ndo_lower_case(self)\n    Returns the lowercasing flag.\nvocab_size(self)\n    Returns the size of the vocabulary.\nset_vocab(self, vocab)\n    Sets the vocabulary.\nget_vocab(self)\n    Gets the vocabulary.\n_tokenize(self, text)\n    Returns the tokenized text.\n_convert_token_to_id(self, token)\n    Converts a token in an id.\n_convert_id_to_token(self, index)\n    Converts an index in a token.\nconvert_tokens_to_string(self, tokens)\n    Converts a sequence of tokens in a single string.</p>\n", "bases": "transformers.tokenization_utils.PreTrainedTokenizer"}, {"fullname": "rate_severity_of_toxic_comments.tokenizer.NaiveTokenizer.__init__", "modulename": "rate_severity_of_toxic_comments.tokenizer", "qualname": "NaiveTokenizer.__init__", "type": "function", "doc": "<p>Initializes the model.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>do_lower_case</strong> (bool, default True):\nLowercasing flag.</li>\n<li><strong>never_split</strong> (list, optional):\nList of tokens which will never be split during tokenization.</li>\n<li><strong>unk_token</strong> (str):\nUnkown token string.</li>\n<li><strong>pad_token</strong> (str):\nPad token string.</li>\n<li><strong>**kwargs</strong> (dict, optional):\nExtra arguments.</li>\n</ul>\n", "signature": "(\n    self,\n    do_lower_case=True,\n    never_split=None,\n    unk_token='[UNK]',\n    pad_token='[PAD]',\n    **kwargs\n)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.tokenizer.NaiveTokenizer.do_lower_case", "modulename": "rate_severity_of_toxic_comments.tokenizer", "qualname": "NaiveTokenizer.do_lower_case", "type": "variable", "doc": "<p>Returns the lowercasing flag.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>lower_case</strong> (bool):\nLowercasing flag.</li>\n</ul>\n"}, {"fullname": "rate_severity_of_toxic_comments.tokenizer.NaiveTokenizer.vocab_size", "modulename": "rate_severity_of_toxic_comments.tokenizer", "qualname": "NaiveTokenizer.vocab_size", "type": "variable", "doc": "<p>Returns the size of the vocabulary.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>vocab_size</strong> (int):\nSize of the vocabulary.</li>\n</ul>\n"}, {"fullname": "rate_severity_of_toxic_comments.tokenizer.NaiveTokenizer.set_vocab", "modulename": "rate_severity_of_toxic_comments.tokenizer", "qualname": "NaiveTokenizer.set_vocab", "type": "function", "doc": "<p>Sets the vocabulary.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>vocab</strong> (dict):\nVocabulary.</li>\n</ul>\n", "signature": "(self, vocab)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.tokenizer.NaiveTokenizer.get_vocab", "modulename": "rate_severity_of_toxic_comments.tokenizer", "qualname": "NaiveTokenizer.get_vocab", "type": "function", "doc": "<p>Gets the vocabulary.</p>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>vocab</strong> (dict):\nVocabulary.</li>\n</ul>\n", "signature": "(self)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.tokenizer.NaiveTokenizer.convert_tokens_to_string", "modulename": "rate_severity_of_toxic_comments.tokenizer", "qualname": "NaiveTokenizer.convert_tokens_to_string", "type": "function", "doc": "<p>Converts a sequence of tokens in a single string.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>tokens</strong> (list):\nList of tokens.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>out_string</strong> (str):\nOutput string.</li>\n</ul>\n", "signature": "(self, tokens)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.tokenizer.create_recurrent_model_tokenizer", "modulename": "rate_severity_of_toxic_comments.tokenizer", "qualname": "create_recurrent_model_tokenizer", "type": "function", "doc": "<p>Creates a recurrent model tokenizer.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>config</strong> (dict):\nConfiguration parameters.</li>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nDataset.</li>\n<li><strong>verbose</strong> (bool, default False):\nVerbosity flag.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>tokenizer</strong> (rate_severity_of_toxic_comments.tokenizer.NaiveTokenizer):\nTokenizer.</li>\n<li><strong>embedding_matrix</strong> (numpy.ndarray):\nEmbedding matrix.</li>\n</ul>\n", "signature": "(config, df, verbose=False)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.training", "modulename": "rate_severity_of_toxic_comments.training", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.training.run_training", "modulename": "rate_severity_of_toxic_comments.training", "qualname": "run_training", "type": "function", "doc": "<p>Executes the full train test loop with the given parameters.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>run_mode</strong> (str):\nRun mode.</li>\n<li><strong>training_data</strong> (torch.utils.data.dataset.Dataset):\nTraining dataset.</li>\n<li><strong>val_data</strong> (torch.utils.data.dataset.Dataset):\nValidation dataset.</li>\n<li><strong>training_params</strong> (dict):\nTraining parameters.</li>\n<li><strong>model_params</strong> (dict):\nModel parameters.</li>\n<li><strong>support_bag</strong> (dict):\nConfiguration parameters.</li>\n<li><strong>seed</strong> (int):\nSeed for random state.</li>\n<li><strong>use_wandb</strong> (bool):\nWeights &amp; Biases flag.</li>\n<li><strong>use_gpu</strong> (bool):\nGPU use flag.</li>\n<li><strong>verbose</strong> (bool, default True):\nVerbosity flag.</li>\n<li><strong>log_interval</strong> (int, deafult 100):\nLogging interval.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>model</strong> (torch.nn.modules.module.Module):\nNeural network model.</li>\n<li><strong>loss_history</strong> (dict):\nLoss history dictionary.</li>\n</ul>\n", "signature": "(\n    run_mode,\n    training_data: torch.utils.data.dataset.Dataset,\n    val_data: torch.utils.data.dataset.Dataset,\n    training_params,\n    model_params,\n    support_bag,\n    seed,\n    use_wandb,\n    use_gpu,\n    verbose: bool = True,\n    log_interval=100\n)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.training.test_loop", "modulename": "rate_severity_of_toxic_comments.training", "qualname": "test_loop", "type": "function", "doc": "<p>Executes the testing loop on the given parameters.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataloader</strong> (torch.utils.data.dataloader.DataLoader):\nDataloader.</li>\n<li><strong>model</strong> (torch.nn.modules.module.Module):\nNeural network model.</li>\n<li><strong>loss_fn</strong> (torch.nn.modules.loss._Loss):\nLoss function.</li>\n<li><strong>device</strong> (torch.device):\nTesting device.</li>\n<li><strong>log_interval</strong> (int):\nLogging interval.</li>\n<li><strong>dataset_type</strong> (str):\nDataset type.</li>\n<li><strong>use_wandb</strong> (bool, default True):\nWeights &amp; Biases flag.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>total_metrics</strong> (dict):\nDictionary with testing metrics.</li>\n</ul>\n", "signature": "(\n    dataloader,\n    model,\n    loss_fn,\n    device,\n    log_interval,\n    dataset_type,\n    use_wandb=True\n)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.training.train_loop", "modulename": "rate_severity_of_toxic_comments.training", "qualname": "train_loop", "type": "function", "doc": "<p>Executes the training loop on the given parameters.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>dataloader</strong> (torch.utils.data.dataloader.DataLoader):\nDataloader.</li>\n<li><strong>model</strong> (torch.nn.modules.module.Module):\nNeural network model.</li>\n<li><strong>loss_fn</strong> (torch.nn.modules.loss._Loss):\nLoss function.</li>\n<li><strong>device</strong> (torch.device):\nTraining device.</li>\n<li><strong>gradient_clipping</strong> (float):\nMaximum norm of the gradients.</li>\n<li><strong>log_interval</strong> (int):\nLogging interval.</li>\n<li><strong>dataset_type</strong> (str):\nDataset type.</li>\n<li><strong>use_wandb</strong> (bool, default True):\nWeights &amp; Biases flag.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>total_metrics</strong> (dict):\nDictionary with training metrics.</li>\n</ul>\n", "signature": "(\n    dataloader,\n    model,\n    loss_fn,\n    optimizer,\n    device,\n    gradient_clipping,\n    log_interval,\n    dataset_type,\n    use_wandb=True\n)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.utilities", "modulename": "rate_severity_of_toxic_comments.utilities", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.utilities.fix_random_seed", "modulename": "rate_severity_of_toxic_comments.utilities", "qualname": "fix_random_seed", "type": "function", "doc": "<p>Fix random seed.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>seed</strong> (int):\nSeed for random state.</li>\n</ul>\n", "signature": "(seed)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.utilities.obfuscator", "modulename": "rate_severity_of_toxic_comments.utilities", "qualname": "obfuscator", "type": "function", "doc": "<p>Censors bad words.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>text</strong> (str):\nText to censor.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>text</strong> (str):\nCensored text.</li>\n</ul>\n", "signature": "(text)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.utilities.parse_config", "modulename": "rate_severity_of_toxic_comments.utilities", "qualname": "parse_config", "type": "function", "doc": "<p>Parses the configuration file.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>default_filepath</strong> (str):\nDefault configuration filepath.</li>\n<li><strong>local_filepath</strong> (str, optional):\nLocal configuration filepath.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>config</strong> (dict):\nConfiguration dictionary.</li>\n</ul>\n", "signature": "(default_filepath, local_filepath=None)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.utilities.process_config", "modulename": "rate_severity_of_toxic_comments.utilities", "qualname": "process_config", "type": "function", "doc": "<p>Parses the configuration dictionary.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nDataset.</li>\n<li><strong>config</strong> (dict):\nConfiguration dictionary.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>support_bag</strong> (dict):\nConfiguration dictionary.</li>\n</ul>\n", "signature": "(df, config)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.utilities.validate_config", "modulename": "rate_severity_of_toxic_comments.utilities", "qualname": "validate_config", "type": "function", "doc": "<p>Validates the configuration dictionary.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>config</strong> (dict):\nConfiguration dictionary.</li>\n</ul>\n", "signature": "(config)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.vocabulary", "modulename": "rate_severity_of_toxic_comments.vocabulary", "type": "module", "doc": "<p></p>\n"}, {"fullname": "rate_severity_of_toxic_comments.vocabulary.build_vocabulary", "modulename": "rate_severity_of_toxic_comments.vocabulary", "qualname": "build_vocabulary", "type": "function", "doc": "<p>Builds vocabulary.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>df</strong> (pandas.core.frame.DataFrame):\nDataset.</li>\n<li><strong>cols</strong> (list):\nList of columns.</li>\n<li><strong>tokenizer</strong> (transformers.models.bert.tokenization_bert.BasicTokenizer):\nTokenizer.</li>\n<li><strong>min_freq</strong> (int, default 1):\nMinimum frequency to become part of the vocabulary.</li>\n<li><strong>save_path</strong> (str, optional):\nSaving path of the vocabulary.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>v</strong> (torchtext.vocab.Vocab):\nVocabulary.</li>\n<li><strong>tokenizer</strong> (transformers.models.bert.tokenization_bert.BasicTokenizer):\nTokenizer.</li>\n</ul>\n", "signature": "(df, cols, tokenizer, min_freq=1, save_path=None)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.vocabulary.get_preprocess_filenames", "modulename": "rate_severity_of_toxic_comments.vocabulary", "qualname": "get_preprocess_filenames", "type": "function", "doc": "<p>Gets the appropriate vocabulary file path to load.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>pipelines</strong> (list):\nList of preprocessing pipelines.</li>\n<li><strong>vocab_file</strong> (str):\nPath of vocabulary file.</li>\n<li><strong>dataset_file</strong> (str, optional):\nPath of dataset file.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>vocab_to_load</strong> (str):\nPath of vocabulary file to load.</li>\n<li><strong>dataset_to_load</strong> (str, optional):\nPath of dataset to load.</li>\n</ul>\n", "signature": "(pipelines, vocab_file, dataset_file=None)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.vocabulary.load_vocabulary", "modulename": "rate_severity_of_toxic_comments.vocabulary", "qualname": "load_vocabulary", "type": "function", "doc": "<p>Loads a vocabulary file into a dictionary.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>vocab_file</strong> (str):\nPath of vocabulary file.</li>\n</ul>\n\n<h6 id=\"returns\">Returns</h6>\n\n<ul>\n<li><strong>vocab</strong> (torchtext.vocab.Vocab):\nVocabulary.</li>\n</ul>\n", "signature": "(vocab_file)", "funcdef": "def"}, {"fullname": "rate_severity_of_toxic_comments.vocabulary.save_vocabulary", "modulename": "rate_severity_of_toxic_comments.vocabulary", "qualname": "save_vocabulary", "type": "function", "doc": "<p>Save the vocabulary to a given file path.</p>\n\n<h6 id=\"parameters\">Parameters</h6>\n\n<ul>\n<li><strong>save_path</strong> (str):\nSaving path of the vocabulary.</li>\n<li><strong>vocab</strong> (torchtext.vocab.Vocab):\nVocabulary.</li>\n</ul>\n", "signature": "(save_path, vocab)", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();