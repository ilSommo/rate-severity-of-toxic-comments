{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from rate_severity_of_toxic_comments.utilities import *\n",
    "from rate_severity_of_toxic_comments.model import *\n",
    "from rate_severity_of_toxic_comments.dataset import *\n",
    "from rate_severity_of_toxic_comments.training import * \n",
    "from rate_severity_of_toxic_comments.preprocessing import * \n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CONFIG_FILE_PATH = \"config/default.json\"\n",
    "LOCAL_CONFIG_FILE_PATH = \"config/local.json\"\n",
    "\n",
    "\n",
    "default = open(DEFAULT_CONFIG_FILE_PATH)\n",
    "CONFIG = json.load(default)\n",
    "\n",
    "if os.path.exists(LOCAL_CONFIG_FILE_PATH):\n",
    "    with open(LOCAL_CONFIG_FILE_PATH) as local:\n",
    "        CONFIG.update(json.load(local))\n",
    "\n",
    "CONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "# CONFIG['group'] = f'{HASH_NAME}-Baseline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"res/data/weighted_train_small.csv\")\n",
    "# df = pd.read_csv(\"res/data/validation_data.csv\")\n",
    "df = df.sample(20)\n",
    "data_size = len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.7\n",
    "threshold_index = int(train_split * data_size)\n",
    "\n",
    "df_train = df[:threshold_index].reset_index(drop=True)\n",
    "df_valid = df[threshold_index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_pipelines = CONFIG['preprocessing']\n",
    "\n",
    "### JUST FOR TESTING APPLIED ALSO ON VALIDATION SET\n",
    "\n",
    "for df in [df_train, df_valid]:\n",
    "    df = apply_preprocessing_pipelines(df, preproc_pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, val_data = build_datasets([df_train, df_valid], CONFIG, [\"weighted\", \"weighted\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtoxicity\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/toxicity/rate-comments/runs/24oip0sy\" target=\"_blank\">pious-plant-45</a></strong> to <a href=\"https://wandb.ai/toxicity/rate-comments\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n",
      "C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Lr: 0.00010000  | Time one epoch (s): 13.6047  \n",
      " Train -  Loss: [3353495.7500]  \n",
      " Val   -  Loss: [9822592.0000] \n",
      "Epoch: 2  Lr: 0.00010000  | Time one epoch (s): 12.8176  \n",
      " Train -  Loss: [3352563.5000]  \n",
      " Val   -  Loss: [9819861.0000] \n",
      "Epoch: 3  Lr: 0.00010000  | Time one epoch (s): 12.6170  \n",
      " Train -  Loss: [3351630.5000]  \n",
      " Val   -  Loss: [9817129.0000] \n",
      "Epoch: 4  Lr: 0.00010000  | Time one epoch (s): 12.0133  \n",
      " Train -  Loss: [3350698.7500]  \n",
      " Val   -  Loss: [9814399.0000] \n",
      "Epoch: 5  Lr: 0.00010000  | Time one epoch (s): 12.4276  \n",
      " Train -  Loss: [3349766.5000]  \n",
      " Val   -  Loss: [9811666.0000] \n",
      "Epoch: 6  Lr: 0.00010000  | Time one epoch (s): 12.4227  \n",
      " Train -  Loss: [3348834.2500]  \n",
      " Val   -  Loss: [9808935.0000] \n",
      "Epoch: 7  Lr: 0.00010000  | Time one epoch (s): 12.6462  \n",
      " Train -  Loss: [3347902.2500]  \n",
      " Val   -  Loss: [9806205.0000] \n",
      "Epoch: 8  Lr: 0.00010000  | Time one epoch (s): 12.1918  \n",
      " Train -  Loss: [3346970.2500]  \n",
      " Val   -  Loss: [9803474.0000] \n",
      "Epoch: 9  Lr: 0.00010000  | Time one epoch (s): 12.5363  \n",
      " Train -  Loss: [3346038.2500]  \n",
      " Val   -  Loss: [9800745.0000] \n",
      "Epoch: 10  Lr: 0.00010000  | Time one epoch (s): 12.6212  \n",
      " Train -  Loss: [3345106.2500]  \n",
      " Val   -  Loss: [9798017.0000] \n",
      "Time for 10 epochs (s): 125.904\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 17696... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>valid_loss</td><td>█▇▆▆▅▄▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>3345106.25</td></tr><tr><td>valid_loss</td><td>9798017.0</td></tr></table>\n",
       "</div></div>\n",
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">pious-plant-45</strong>: <a href=\"https://wandb.ai/toxicity/rate-comments/runs/24oip0sy\" target=\"_blank\">https://wandb.ai/toxicity/rate-comments/runs/24oip0sy</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220118_191839-24oip0sy\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = run_training(training_data, val_data, log_interval=10, config=CONFIG, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ffadaf9e10aa498c9f8f983807a351c552daa3bebeb8809def47b936e4fb9c51"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('rate-severity-of-toxic-comments-gIPSL8Vl': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
